{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Maximum Likelihood Estimation (MLE)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-requisite knowledge: Random Variables, Linear Algebra, Optimization, Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum Likelihood Estimation (MLE) is a statistical tool to estimate the parameters of a model given some observed data. The goal is to find the parameters that maximize the likelihood of the data given the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve MLE, we need to define a likelihood function which is differentiable, so we can optimize the function by taking a partial derivative with respect to the parameters we want to estimate.\n",
    "\n",
    "The Likelihood function $L(\\theta | x_1,..., x_n) = f(x_1,..., x_n | \\theta)$ is the probability of observing data x given some parameters $\\theta$. The point in the parameter space that maximizes the likelihood function is the estimate of the parameters that best fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given observations $x_1,....,x_n$ from a gaussian distribution with unknown mean $\\mu$ and unknown variance $\\sigma^2$, what are the estimates of $\\mu$, $\\sigma^2$ that maximize the likelihood function?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define the Likelihood function $L(\\theta | x_1, ...., x_n)$\n",
    "\n",
    "For a gaussian distribution, the likelihood function is given by:\n",
    "$$L(\\mu, \\sigma^2) = \\prod_{i=1}^n f(x_i | \\mu, \\sigma^2) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp(-\\frac{(x_i - \\mu)^2}{2\\sigma^2})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above equation looks scary and complicated to optimize. We can simplify the likelihood function by taking the log of the likelihood function and then taking the derivative of the log likelihood function.\n",
    "\n",
    "Another reason why we take the log of the likelihood function is because likelihoods can get really small  which causes round-off errors and numerical instability or they can get really large which can cause overflow errors.\n",
    "\n",
    "$$l(\\mu, \\sigma^2) = \\ln L(\\mu, \\sigma^2) = \\sum_{i=1}^n \\ln \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp(-\\frac{(x_i - \\mu)^2}{2\\sigma^2})$$\n",
    "\n",
    "$$ = \\sum_{i=1}^n \\ln \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} + \\sum_{i=1}^n \\ln \\exp(-\\frac{(x_i - \\mu)^2}{2\\sigma^2})$$\n",
    "\n",
    "$$ = -\\frac{n}{2}\\ln(2 \\pi \\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's optimize for $\\mu$ by taking the partial derviative of the simplified log likelihood we derived above and setting it = 0\n",
    "\n",
    "$$\\frac{\\partial l(\\mu, \\sigma^2)}{\\partial \\mu} = \\frac{\\partial}{\\partial \\mu} \\left(-\\frac{n}{2}\\ln(2 \\pi \\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\right)$$\n",
    "\n",
    "$$ 0 - \\frac{1}{\\sigma^2} \\sum_{i=1}^n 2(x_i - \\mu)(-1) = 0 $$\n",
    "\n",
    "$$\\mu_{mle} = \\frac{\\sum_{i=1}^n x_i}{n}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will optimize for the variance $\\sigma^2$ by taking the partial derivative of the simplified log likelihood we derived above and setting it = 0\n",
    "\n",
    "$$\\frac{\\partial l(\\mu, \\sigma^2)}{\\partial \\sigma^2} = \\frac{\\partial}{\\partial \\sigma^2} \\left(-\\frac{n}{2}\\ln(2 \\pi \\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\right)$$\n",
    "\n",
    "\n",
    "$$0 = -\\frac{n}{2} (\\frac{2 \\pi}{2 \\pi \\sigma^2}) + \\frac{1}{2\\sigma^4}\\sum_{i=1}^n (x_i - \\mu)^2 $$\n",
    "\n",
    "$$\\sigma^2_{mle} = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\mu)^2$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: While the MLE estimate for $\\mu$ is unbiased and consistent, the MLE estimate for $\\sigma^2$ is biased. The unbiased estimate for $\\sigma^2$ is given by:\n",
    "\n",
    "$$\\sigma^2_{unbiased} = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\mu)^2$$\n",
    "\n",
    "It is important to keep in mind that MLE will not always reuslt in the best estimate for the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.medicine.mcgill.ca/epidemiology/hanley/bios601/Likelihood/Likelihood.pdf"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
